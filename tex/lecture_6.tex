\documentclass[11pt,
			   %10pt, 
               %hyperref={colorlinks},
               aspectratio=169,
               hyperref={colorlinks}
               ]{beamer}
\usetheme{Singapore}
\usecolortheme[snowy, cautious]{owl}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[american]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    urlcolor=[rgb]{0,0,0.61},
    linkcolor=[rgb]{0,0,0.61}}
\definecolor{magenta}{RGB}{255, 0, 255}
     
\usepackage[natbib=true,style=authoryear,backend=bibtex,useprefix=true]{biblatex}

%\setbeamercolor*{bibliography entry title}{fg=black}
%\setbeamercolor*{bibliography entry location}{fg=black}
%\setbeamercolor*{bibliography entry note}{fg=black}
\definecolor{OwlGreen}{RGB}{51,0,102} % easier to see
\setbeamertemplate{bibliography item}{}
\setbeamerfont{caption}{size=\footnotesize}
\setbeamertemplate{frametitle continuation}{}
\setcounter{tocdepth}{1}
\renewcommand*{\bibfont}{\scriptsize}
\addbibresource{lecture_6.bib}

\renewcommand*{\thefootnote}{\fnsymbol{footnote}}

\usenavigationsymbolstemplate{}
\setbeamertemplate{footline}{%
    \raisebox{5pt}{\makebox{\hfill\makebox[20pt]{\color{gray}
          \scriptsize\insertframenumber}}}\hspace*{5pt}}

          
\author{Patrick Hall}
\title{Responsible Machine Learning\footnote{\tiny{This material is shared under a \href{https://creativecommons.org/licenses/by/4.0/deed.ast}{CC By 4.0 license} which allows for editing and redistribution, even for commercial purposes. However, any derivative work should attribute the author.}}}
\subtitle{Lecture 6: Responsible Machine Learning Best Practices}
\institute{The George Washington University}
\date{\today}


\begin{document}
	
	\maketitle
	
	\begin{frame}
	
		\frametitle{Contents}
		
		\tableofcontents{}
		
	\end{frame}

	%-------------------------------------------------------------------------------
	\section{Technical Solutions}
	%-------------------------------------------------------------------------------

		\subsection*{}
		
			\begin{frame}				
				%A Responsible Machine Learning Workflow
				\frametitle{Responsible ML Blueprint\footnote{\tiny{This blueprint does not address ETL workflows.}}}
								
				\begin{figure}[htb]
					\begin{center}
						%\includegraphics[height=150pt]{../img/blueprint.png}
						\includegraphics[height=150pt]{../img/rml_diagram_no_hilite.png}
						\label{fig:blueprint}
					\end{center}
				\end{figure}		
			
			\end{frame}
		
			\begin{frame}
			
				\frametitle{EDA and Data Visualization}		
				
				\begin{columns}
		
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/eda.png}
					
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item Know thy data.
						%\item \textbf{Automation} implemented in Driverless AI as AutoViz.
						\item OSS: \href{http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/aggregator.html}{H2O-3 Aggregator}
						\item References: \citefield{wilkinson2018visualizing}{title}; \citefield{wilkinson2006grammar}{title}
					\end{itemize}
					
				\end{columns}
			
			\end{frame}
					
			\begin{frame}

				\frametitle{Interlude: My Favorite Visualizations}		
			
				\vspace{-15pt}
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=160pt]{../img/net_graph.png}
					
					\tiny{A network graph capturing the Pearson correlation relationships between many \textit{columns} in a lending dataset.}
				
					\column{0.5\linewidth}
					
					\vspace{19pt}
					\centering
					\includegraphics[height=120pt]{../img/ae.png}
					
					\vspace{19pt}
					
					\tiny{An autoencoder projection of the MNIST data. Projections capture sparsity, clusters, hierarchy, and outliers in \textit{rows} of a dataset.}
				
				\end{columns}
			
				\vspace{10pt}
			
				\centering
				\footnotesize{Both of these images capture high-dimensional datasets in just two dimensions.}
		
			\end{frame}
	
			\begin{frame}
			
				\frametitle{Establish Benchmarks}		
	
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/bench.png}
					\end{center}
				\end{figure}	
	
				\vspace{-10pt}
				\scriptsize{Establishing reproducible benchmarks from which to gauge improvements in accuracy, fairness, interpretability or privacy is crucial for good (``data'') science and for compliance. }
			
			\end{frame}
	
			\begin{frame}
		
				\frametitle{Manual, Private, Sparse or Straightforward Feature Engineering }		
		
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/fe.png}
				
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item OSS: \href{https://cran.r-project.org/web/packages/elasticnet/index.html}{elasticnet}, \href{https://index.pocketcluster.io/featuretools-featuretools.html}{Feature Tools}
						\item References: \citefield{zou2006sparse}{title}; \citefield{kanter2016label}{title}; \citefield{t_closeness}{title}
					\end{itemize}
				
				\end{columns}		
		
			\end{frame}
		
			\begin{frame}
		
				\frametitle{Preprocessing for Fairness, Privacy or Security}		
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/pre.png}
				
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item OSS: IBM \href{https://github.com/IBM/AIF360}{AIF360} and \href{https://github.com/IBM/differential-privacy-library}{diffprivlib}
						\item References: \citefield{kamiran2012data}{title}; \citefield{feldman2015certifying}{title}; \citefield{calmon2017optimized}{title}; \citefield{agrawal2000privacy}{title}; \citefield{ji2014differential}{title}
					\end{itemize}
				
				\end{columns}			
			
			\end{frame}
				
			\begin{frame}
		
				\frametitle{Constrained, Fair, Interpretable, Private or Simple Models}		
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					%\includegraphics[height=120pt]{../img/im.png}
	    			\includegraphics[height=120pt]{../img/rml_diagram_lec1_hilite.png}
					\column{0.5\linewidth}
					\vspace{-5pt}
					\small
					\begin{itemize}
						\item OSS: \href{https://github.com/interpretml/interpret}{\citefield{ga2m}{title} (GA2M/EBM)}; \href{https://users.cs.duke.edu/~cynthia/code.html}{Rudin Group models} e.g. \citefield{sbrl}{title} (SBRL); Monotonic gradient boosting machines in \href{https://github.com/h2oai/h2o-3/blob/master/h2o-py/demos/H2O_tutorial_gbm_monotonicity.ipynb}{H2O-3} or \href{https://xiaoxiaowang87.github.io/monotonicity_constraint/}{XGBoost}; \href{https://docs.pymc.io/}{pymc3}
						\item References: \citefield{pate}{title}; \citefield{zhang2018mitigating}{title}; \citefield{pearl2011bayesian}{title}; \citefield{wf_xnn}{title} (XNN)
					\end{itemize}
					\normalsize
				
				\end{columns}			
			
			\end{frame}
	
			\begin{frame}
		
				\frametitle{Prediction Calibration}		
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/calibrate.png}
				
					\column{0.5\linewidth}
					\begin{itemize}
						\item Just because a number is in $[0,1]$ does not make it a probability. 
						\item OSS: \href{https://scikit-learn.org/stable/modules/calibration.html}{scikit-learn} 
						\item References: \citefield{niculescu2005predicting}{title}
					\end{itemize}
				
				\end{columns}			

			\end{frame}
	
			\begin{frame}
		
				\frametitle{Traditional Model Assessment and Diagnostics}		
			
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/ma.png}
					\end{center}
				\end{figure}	

			\vspace{-10pt}
			\scriptsize{Residual analysis, Q-Q plots, AUC and lift curves etc. confirm model is accurate and meets assumption criteria.}
		
			\end{frame}
					
			\begin{frame}
		
				\frametitle{Post-hoc Explanations}		
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/exp.png}
				
					\column{0.5\linewidth}
					\vspace{-5pt}
					
					\small{
					\begin{itemize}
						\item Explanations enable \textit{understanding} and \textit{appeal} ... \textit{not trust}.
						\item OSS: \href{https://github.com/SeldonIO/alibi}{alibi}, \href{https://github.com/slundberg/shap}{shap} 
						\item References: \citefield{wachter2017counterfactual}{title}; \citefield{shapley}{title}; \citefield{dt_surrogate2}{title}; \citefield{please_stop}{title} (criticism)
					\end{itemize}}
				
				\end{columns}
		
			\end{frame}
	
			\begin{frame}
		
				\frametitle{Interlude: The Time--Tested Shapley Value}		
			
				\begin{enumerate}
				
					\item \textbf{In the beginning}: \citefield{shapley1953value}{title}, \citefield{shapley1953value}{year}
					\item \textbf{Nobel-worthy contributions}: \citefield{shapley1988shapley}{title}, \citefield{shapley1988shapley}{year}
					\item \textbf{Shapley regression}: \citefield{lipovetsky2001analysis}{title}, \citefield{lipovetsky2001analysis}{year}
					\item \textbf{First reference in ML?} \citefield{keinan2004fair}{title}, \citefield{keinan2004fair}{year} 	
					\item \textbf{Into the ML research mainstream, i.e. JMLR}: \citefield{kononenko2010efficient}{title}, \citefield{kononenko2010efficient}{year}
					\item \textbf{Into the real-world data mining workflow ... \textit{finally}}: \citefield{tree_shap}{title}, \citefield{tree_shap}{year}	
					\item \textbf{Unification}: \citefield{shapley}{title}, \citefield{shapley}{year}	
				
				\end{enumerate}
			
			\end{frame}
	
			\begin{frame}
		
				\frametitle{Model Debugging for Accuracy, Privacy or Security}		
			
				\begin{columns}
	
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/md.png}
				
					\column{0.5\linewidth}
					\vspace{-5pt}
					\scriptsize
					{\begin{itemize}
						\item Eliminating errors in model predictions by testing: adversarial examples, explanation of residuals, random attacks and ``what-if'' analysis.
						\item OSS: \href{https://github.com/tensorflow/cleverhans}{cleverhans}, \href{https://github.com/SauceCat/PDPbox}{pdpbox}, \href{https://pair-code.github.io/what-if-tool/index.html}{what-if tool},
						\href{https://github.com/MadryLab/robustness}{robustness}
						\item References: \citefield{amershi2015modeltracker}{title}; \citefield{papernot2018marauder}{title}; \citefield{security_of_ml}{title}
					\end{itemize}}
					\normalsize
				
				\end{columns}			
			
			\end{frame}
			
			\begin{frame}	
			
				\frametitle{Machine Learning Attacks\footnote{\tiny{See \url{https://github.com/jphall663/secure_ML_ideas} for full size image and more information.}}}		
			
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=160pt]{../img/Attack_Cheat_Sheet.png}
					\end{center}
				\end{figure}	
			\end{frame}
			
			\begin{frame}		
			
				\frametitle{Post-hoc Disparate Impact Assessment and Remediation}		
				
				\begin{columns}
		
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/fair.png}
					
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item Social bias testing should include group fairness tests and should attempt to consider individual fairness. 
						\item OSS: \href{https://github.com/dssg/aequitas}{aequitas}, IBM \href{https://github.com/IBM/AIF360}{AIF360}, \href{https://github.com/LASER-UMASS/Themis}{themis}
						\item References: \citefield{dwork2012fairness}{title}; \citefield{kamiran2012decision}{title}; \citefield{hardt2016equality}{title}; \citefield{feldman2015certifying}{title} 
					\end{itemize}
					
				\end{columns}
			
			\end{frame}
	
			\begin{frame}
			
				\frametitle{Quantify and Plan for Risk}	
				
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/risk.png}
						\end{center}
					\end{figure}	
	
				\vspace{-10pt}
				\scriptsize{Your model will be wrong. Stake-holders need to understand and be prepared for the human and financial costs of these wrong decisions.}	
					
			\end{frame}
	
			\begin{frame}
			
				\frametitle{Human Review and Documentation}		
				
				\begin{columns}
		
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/hr.png}
					
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item Reference: \citefield{model_cards}{title}
						\item Documentation of considered alternative approaches typically necessary for compliance.
					\end{itemize}
					
				\end{columns}
			
			\end{frame}
	
			\begin{frame}
	
				\frametitle{Deployment, Management and Monitoring}		
				
				\begin{columns}
		
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/deploy.png}
					
					\column{0.5\linewidth}
					\vspace{-5pt}
					\begin{itemize}
						\item Monitor models for accuracy, disparate impact, privacy violations or security vulnerabilities in real-time; track model and data lineage.
						\item OSS: 
						\href{https://dvc.org/}{DVC},
						\href{https://gigantum.com/}{gigantum}, 
						\href{https://www.kubeflow.org/docs/pipelines/overview/pipelines-overview/}{KubeFlow},
						\href{https://github.com/mlflow/mlflow}{mlflow}, 
						\href{https://github.com/mitdbg/modeldb}{modeldb},
						\href{link:https://www.tensorflow.org/tfx/guide/mlmd}{TensorFlow ML Metadata}, 
						\href{https://www.tensorflow.org/tfx}{TensorFlow TFX},
						\href{https://github.com/EthicalML/awesome-machine-learning-operations}{awesome-machine-learning-ops metalist}
						\item Reference: \citefield{vartak2016m}{title}
					\end{itemize}
					
				\end{columns}
			
			\end{frame}

			\begin{frame}
	
				\frametitle{Kill Switches}	
				
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/kill.png}
					\end{center}
				\end{figure}	
				
				\vspace{-10pt}
				\scriptsize{Being able to quickly turn off a misbehaving ML system is crucially important. This requires technical and organizational considerations. E.g., how much revenue is lost each minute a model is disabled?}	
				
				
			\end{frame}
	
			\begin{frame}	
			
				\frametitle{Human Appeal}		
				
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/ha.png}
					\end{center}
				\end{figure}	
	
				%\vspace{-10pt}
				\footnotesize{\textit{Very} important, may require custom implementation for each deployment environment? Related problems exist \href{https://www.nytimes.com/2017/06/13/opinion/how-computers-are-harming-criminal-justice.html}{\textit{today}}}.
	
			\end{frame}
	
			\begin{frame}	
				\frametitle{Decommission Model}		
				
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/zde.png}
					\end{center}
				\end{figure}	
	
				%\vspace{-10pt}
				\footnotesize{When a model becomes absolutely or relatively inaccurate, unfair, or insecure it must be taken out of service, but saved in an executable and reproducible manner.}
	
			\end{frame}
	
			\begin{frame}
			
				\frametitle{Causality?}	
				
				\begin{columns}
		
					\column{0.5\linewidth}
					\centering
					\includegraphics[height=120pt]{../img/cause.png}
					
					\column{0.5\linewidth}
					\begin{itemize}
						\item Root cause analysis: can root causes be identified, verified? Formalized into model architecture? 
						\item OSS: \href{https://github.com/microsoft/dowhy}{dowhy}, \href{https://docs.pymc.io/}{pymc3}
						\item References: \citefield{pearl2018book}{title}; \citefield{salvatier2016probabilistic}{title}
					\end{itemize}
					
				\end{columns}
				
			\end{frame}
	
			\begin{frame}	
	
				\frametitle{Iterate: Use Gained Knowledge to Improve Accuracy, Fairness, Interpretability, Privacy or Security}		
				
				\begin{figure}[htb]
					\begin{center}
						\includegraphics[height=135pt]{../img/iter.png}
						\label{fig:blueprint}
					\end{center}
				\end{figure}	
	
				\centering
				Improvements, KPIs should not be restricted to accuracy alone.
			
			\end{frame}

	%-------------------------------------------------------------------------------
	\section{Process Solutions}
	%-------------------------------------------------------------------------------

		\begin{frame}
	
			\frametitle{Process Solutions}
			
			\begin{itemize}
				
				\item \textbf{Bug Bounties}: Offer rewards to the broader community to find all kinds of problems (discrimination, opacity, vulnerabilities, privacy harms, etc.) in your organization's public-facing ML systems. 
				
				\item \textbf{Data and AI Principles}: Devise central tenants for how your organization will handle ethical, political, and legal issues related to data and ML.
				
				\item \textbf{Diversity of Experience}: Ensure data and ML teams are staffed with individuals that can share different demographic, technical, and professional perspectives. 
				
			\end{itemize}
					
		\end{frame}
		
		\begin{frame}
		
			\frametitle{Process Solutions}
			
			\begin{itemize}
				
				\item \textbf{"Dog-fooding"}: If possible, test your ML system on yourself or internally at your organization. Don't feel comfortable using it on yourself? Maybe you shouldn't release it. 

				\item \textbf{Documentation}: Documentation ends up being the primary physical implementation of many risk controls. 

				\item \textbf{Domain Expertise}: Success in ML almost always requires input from humans with deep understanding of the problem domain. 
				
				\item \textbf{Effective Challenge and Human Review}: Nearly all aspects of ML workflows should involve challenges and questioning from group members. This can be in the form of human interrogation of ML-related processes or in the form of challenger models. 
				
				\item \textbf{Executive Oversight}: An empowered executive with a staff and budget can exert a strong influence over organizational use of ML.
				
			\end{itemize}
			
		\end{frame}
		
		\begin{frame}
			
			\frametitle{Process Solutions}	
				
			\begin{itemize}
				
				\item \textbf{Incident Response Plans}: Complex ML systems \textit{will} fail. Being prepared for failures or attacks can be the difference between a major incident and a minor disruption.
				
				\item \textbf{Incentives}: Model builders, testers, auditors, and executives all have different roles to play in the implementation of responsible ML and should be incentivized to play the correct role.
				
				\item \textbf{Legal Privilege}: Consider use of privilege to minimize risk when dealing with ML-related legal and compliance issues.
				
				\item \textbf{Model Risk Management}: The established practice of model risk management can be expanded outside of financial services.
				
				\item \textbf{Red-teaming}: Establish a group or hire third-parties to act as adversaries and find problems (discrimination, opacity, vulnerabilities, privacy harms, etc.) in your organization's public-facing ML systems.
				
			\end{itemize}
			
		\end{frame}	

%-------------------------------------------------------------------------------
\section{Acknowledgements} 
%-------------------------------------------------------------------------------

\begin{frame}
	
	\frametitle{Acknowledgments}
	
	Thanks to Lisa Song for her continued assistance in developing these course materials.\\
	\vspace{10pt}
	Some materials \copyright\hspace{1pt}Patrick Hall and the H2O.ai team 2017-2020.  
	
\end{frame}	


%-------------------------------------------------------------------------------
%	\subsection{Questions}
%------------------------------------------------------------------------------

%		\begin{frame}

%			\frametitle{Open Conceptual Questions}		

%			\begin{itemize}
%				\item How much automation is appropriate, 100\%?
%				\item How to automate learning by iteration, reinforcement learning?
%				\item How to implement human appeals, is it productizable?
%			\end{itemize}
			
%		\end{frame}

%-------------------------------------------------------------------------------
%	References
%-------------------------------------------------------------------------------

	\begin{frame}[t, allowframebreaks]
	
		\frametitle{References}	
				
		\printbibliography
		
	\end{frame}

\end{document}