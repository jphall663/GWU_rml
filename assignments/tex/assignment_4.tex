% Copyright Patrick Hall 2021

\documentclass[fleqn]{article}
\renewcommand\refname{}
\title{Responsible Machine Learning\\\Large{Assignment 4}\\\Large{10 points}}
\author{\copyright Patrick Hall 2021}

\usepackage{graphicx}
\usepackage{fullpage}
\usepackage{pdfpages}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{MnSymbol}
\usepackage{enumerate}
\usepackage{setspace}
\usepackage[colorlinks, breaklinks=true]{hyperref} 
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage{color}
\usepackage{listings}
\usepackage{csvsimple}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{verbatim}
\usepackage{mdframed}
\usepackage{changepage}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\begin{document}

\maketitle

\noindent In Assignment 4, you will work with your group to ``red-team'' your best model following the instructions below and treating your best model as a black box. A \href{https://nbviewer.jupyter.org/github/jphall663/GWU_rml/blob/master/assignments/assignment_4/assign_4_template.ipynb?flush_cache=true}{template} has been provided with examples of simple model extraction and adversarial example attacks. For those of you who use Python virtual environments, a basic \href{https://github.com/jphall663/GWU_rml/blob/master/assignments/requirements.txt}{\texttt{requirements.txt}} file is also available for the template.\\

\noindent Please let me know immediately if you find typos or mistakes in this assignment or related materials. 

\section{Conduct a white-hat model extraction attack.}

Cells 10--16 demonstrate a simple, but effective, model extraction attack. My example model extraction attack uses a single decision tree, that I then plot and use to craft adversarial examples. I'd like for you to try a decision tree extraction attack, but you don't have to use my code. I imagine getting \texttt{graphviz} installed could be difficult for some, so feel free to use your favorite kind of decision tree if the template code proves difficult to run. (Basic instructions for installing \texttt{graphviz} are available at the bottom of the \href{https://jphall663.github.io/GWU_rml/}{class website}.)\\

\noindent You may call \texttt{predict()} on your best model only one time to perform the extraction attack.
 
\section{Find adversarial examples for your model.}

Cells 17--20 use the information from the extracted decision tree to craft highly effective adversarial examples. You must create at least one adversarial example (row of data) that can evoke low predictions from your best model, and at least one adversarial example that can evoke high predictions.\\

\noindent You may call \texttt{predict()} on your best model only one time to test your adversarial examples.

\section{Submit Code Results.}

Your deliverable for this assignment is to update your group's GitHub repository to reflect this ``red-teaming'' exercise. The model extraction attack is worth 5 points, and the adversarial examples are worth another 5 points. \\

\noindent In the real world, after performing this analysis, you would want to contact your manager and your organization's IT security team to discuss the vulnerability. You would argue to put in place authentication on the vulnerable model end point and also argue that monitoring the model's production scoring queue for random data and training data would be advisable, if possible.\\

\noindent \textbf{Your deliverables are due Wednesday, June 15\textsuperscript{th}, at 11:59:59 PM ET.}\\

\noindent Note that you may also improve Assignment 1 or 3 scores throughout the Summer I Session to improve your ranking, your Assignment 1 grade, your Assignment 3 grade, and your final project grade. Moving forward, you'll need to be able to show that your new predictions preserve AIR > 0.8 for all protected groups.

\end{document}

